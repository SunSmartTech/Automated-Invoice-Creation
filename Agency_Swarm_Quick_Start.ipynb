{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pSDsePTyLzkZ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SunSmartTech/Automated-Invoice-Creation/blob/master/Agency_Swarm_Quick_Start.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sSR2RQa0Z3V3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c6e7b2a-51ba-4a8a-9d63-c40880da08b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting agency-swarm\n",
            "  Downloading agency_swarm-0.4.4-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.13.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-7.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.55.3 in /usr/local/lib/python3.11/dist-packages (from agency-swarm) (1.59.9)\n",
            "Requirement already satisfied: docstring_parser==0.16 in /usr/local/lib/python3.11/dist-packages (from agency-swarm) (0.16)\n",
            "Collecting pydantic==2.8.2 (from agency-swarm)\n",
            "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datamodel-code-generator==0.26.1 (from agency-swarm)\n",
            "  Downloading datamodel_code_generator-0.26.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting deepdiff==6.7.1 (from agency-swarm)\n",
            "  Downloading deepdiff-6.7.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting termcolor==2.4.0 (from agency-swarm)\n",
            "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting python-dotenv==1.0.1 (from agency-swarm)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting rich==13.7.1 (from agency-swarm)\n",
            "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting jsonref==1.1.0 (from agency-swarm)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting argcomplete<4.0,>=1.10 (from datamodel-code-generator==0.26.1->agency-swarm)\n",
            "  Downloading argcomplete-3.5.3-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting black>=19.10b0 (from datamodel-code-generator==0.26.1->agency-swarm)\n",
            "  Downloading black-24.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting genson<2.0,>=1.2.1 (from datamodel-code-generator==0.26.1->agency-swarm)\n",
            "  Downloading genson-1.3.0-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting inflect<6.0,>=4.1.0 (from datamodel-code-generator==0.26.1->agency-swarm)\n",
            "  Downloading inflect-5.6.2-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting isort<6.0,>=4.3.21 (from datamodel-code-generator==0.26.1->agency-swarm)\n",
            "  Downloading isort-5.13.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: jinja2<4.0,>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from datamodel-code-generator==0.26.1->agency-swarm) (3.1.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datamodel-code-generator==0.26.1->agency-swarm) (24.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from datamodel-code-generator==0.26.1->agency-swarm) (6.0.2)\n",
            "Collecting ordered-set<4.2.0,>=4.0.2 (from deepdiff==6.7.1->agency-swarm)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.8.2->agency-swarm) (0.7.0)\n",
            "Collecting pydantic-core==2.20.1 (from pydantic==2.8.2->agency-swarm)\n",
            "  Downloading pydantic_core-2.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.8.2->agency-swarm) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich==13.7.1->agency-swarm) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich==13.7.1->agency-swarm) (2.18.0)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.7-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.6.0 (from gradio)\n",
            "  Downloading gradio_client-1.6.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.27.1)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.9.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.6.0->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.6.0->gradio) (14.2)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (8.1.8)\n",
            "Collecting primp>=0.10.0 (from duckduckgo-search)\n",
            "  Downloading primp-0.10.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (5.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.55.3->agency-swarm) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.55.3->agency-swarm) (0.8.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Collecting mypy-extensions>=0.4.3 (from black>=19.10b0->datamodel-code-generator==0.26.1->agency-swarm)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black>=19.10b0->datamodel-code-generator==0.26.1->agency-swarm)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black>=19.10b0->datamodel-code-generator==0.26.1->agency-swarm) (4.3.6)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich==13.7.1->agency-swarm) (0.1.2)\n",
            "Collecting email-validator>=2.0.0 (from pydantic[email]!=2.4.0,<3.0,>=1.10.0; python_version >= \"3.11\" and python_version < \"4.0\"->datamodel-code-generator==0.26.1->agency-swarm)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.3.0)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->pydantic[email]!=2.4.0,<3.0,>=1.10.0; python_version >= \"3.11\" and python_version < \"4.0\"->datamodel-code-generator==0.26.1->agency-swarm)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Downloading agency_swarm-0.4.4-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.8/116.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datamodel_code_generator-0.26.1-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepdiff-6.7.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.9/423.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
            "Downloading pydantic_core-2.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.13.1-py3-none-any.whl (57.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.6.0-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.8/321.8 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading duckduckgo_search-7.2.1-py3-none-any.whl (19 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.7-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading primp-0.10.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading argcomplete-3.5.3-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading black-24.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading genson-1.3.0-py3-none-any.whl (21 kB)\n",
            "Downloading inflect-5.6.2-py3-none-any.whl (33 kB)\n",
            "Downloading isort-5.13.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, genson, uvicorn, tomlkit, termcolor, semantic-version, ruff, python-multipart, python-dotenv, pydantic-core, primp, pathspec, ordered-set, mypy-extensions, markupsafe, jsonref, isort, inflect, ffmpy, dnspython, argcomplete, aiofiles, starlette, rich, pydantic, email-validator, duckduckgo-search, deepdiff, black, safehttpx, gradio-client, fastapi, gradio, datamodel-code-generator, agency-swarm\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.5.0\n",
            "    Uninstalling termcolor-2.5.0:\n",
            "      Successfully uninstalled termcolor-2.5.0\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.27.2\n",
            "    Uninstalling pydantic_core-2.27.2:\n",
            "      Successfully uninstalled pydantic_core-2.27.2\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: inflect\n",
            "    Found existing installation: inflect 7.5.0\n",
            "    Uninstalling inflect-7.5.0:\n",
            "      Successfully uninstalled inflect-7.5.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.5\n",
            "    Uninstalling pydantic-2.10.5:\n",
            "      Successfully uninstalled pydantic-2.10.5\n",
            "Successfully installed agency-swarm-0.4.4 aiofiles-23.2.1 argcomplete-3.5.3 black-24.10.0 datamodel-code-generator-0.26.1 deepdiff-6.7.1 dnspython-2.7.0 duckduckgo-search-7.2.1 email-validator-2.2.0 fastapi-0.115.7 ffmpy-0.5.0 genson-1.3.0 gradio-5.13.1 gradio-client-1.6.0 inflect-5.6.2 isort-5.13.2 jsonref-1.1.0 markupsafe-2.1.5 mypy-extensions-1.0.0 ordered-set-4.1.0 pathspec-0.12.1 primp-0.10.1 pydantic-2.8.2 pydantic-core-2.20.1 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.20 rich-13.7.1 ruff-0.9.3 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.45.3 termcolor-2.4.0 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ],
      "source": [
        "!pip install agency-swarm gradio duckduckgo-search"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from agency_swarm import set_openai_key\n",
        "from getpass import getpass\n",
        "set_openai_key(getpass(\"Please enter your openai key: \"))"
      ],
      "metadata": {
        "id": "dHqVhxU-x1rL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d17532ea-ff37-4d32-def1-a15a71655259"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your openai key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Option 1: Use Genesis Agency\n",
        "\n",
        "Genesis agency is a special pre-made agency that will create all your agents for you. All you have to do is send your requirements, mission, apis that you want to connect to. Your agent files will appear under files on the left.\n",
        "\n",
        "### Creating Agents\n",
        "\n",
        "To test this, simply run the cell below and click on the URL. Then, send your agency description. For example:\n",
        "\n",
        "> Please create a social media marketing agency with 3 agents that connects to facebook api\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PAuJDvpOKQqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agency_swarm.agency.genesis import GenesisAgency\n",
        "\n",
        "agency = GenesisAgency(with_browsing=False)\n",
        "\n",
        "demo = agency.demo_gradio(height=900)\n",
        "\n",
        "# example task:\n",
        "# Please create a social media marketing agency with 3 agents that connects to facebook api"
      ],
      "metadata": {
        "id": "nodGJXp7Krmn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "2589c3e4-c4a9-4b6c-cbfc-3fb51746f31c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/components/chatbot.py:282: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://fd664d0f0caaf1bc2a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://fd664d0f0caaf1bc2a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running Your New Agency\n",
        "\n",
        "All your agent files will appear in `files` on the left. You can then copy them to your local PC and continue working, or modify them directly in Google Collab.\n",
        "\n",
        "To run your new agency, simply replace `<YOUR_AGENCY_NAME>` with the name of your agency folder on the left and run the cell below."
      ],
      "metadata": {
        "id": "2Ckrh7jhKrTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from SocialMediaMasters.agency import agency\n",
        "from SolarSteve.agency import agency\n",
        "\n",
        "if demo:\n",
        "  demo.close()\n",
        "\n",
        "demo = agency.demo_gradio(height=900)"
      ],
      "metadata": {
        "id": "yZ5AcEZ8MEA6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "outputId": "e5fd85d5-a1de-42fa-a61a-1d389feb1e94"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/components/chatbot.py:282: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6cd131bd8f85a9bd19.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6cd131bd8f85a9bd19.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Option 2: Create Agents From Scratch."
      ],
      "metadata": {
        "id": "OZV8BiryKhsI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CEO Agent\n"
      ],
      "metadata": {
        "id": "1h43Eh0PSDHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ceo_instructions = \"\"\"# Instructions for CEO Agent\n",
        "\n",
        "- Ensure that proposal is send to the user before proceeding with task execution.\n",
        "- Delegate tasks to appropriate agents, ensuring they align with their expertise and capabilities.\n",
        "- Clearly define the objectives and expected outcomes for each task.\n",
        "- Provide necessary context and background information for successful task completion.\n",
        "- Maintain ongoing communication with agents until complete task execution.\n",
        "- Review completed tasks to ensure they meet the set objectives.\n",
        "- Report the results back to the user.\"\"\""
      ],
      "metadata": {
        "id": "w7xwtx3-LWna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agency_swarm import Agent\n",
        "\n",
        "ceo = Agent(name=\"CEO\",\n",
        "            description=\"Responsible for client communication, task planning and management.\",\n",
        "            instructions=ceo_instructions, # can be a file like ./instructions.md\n",
        "            files_folder=None,\n",
        "            tools=[])"
      ],
      "metadata": {
        "id": "NKFbvF54SGT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Virtual Assistant"
      ],
      "metadata": {
        "id": "y_9zs8XLrkal"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing tools from langchain example.  \n",
        "You can skip these and remove them from va agent below."
      ],
      "metadata": {
        "id": "pSDsePTyLzkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "|!pip install langchain==0.0.318 &> /dev/null"
      ],
      "metadata": {
        "id": "sY8FY_UwLKy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.utilities.zapier import ZapierNLAWrapper\n",
        "from langchain.agents.agent_toolkits import ZapierToolkit\n",
        "import os\n",
        "from langchain.tools import format_tool_to_openai_function\n",
        "from langchain.tools.zapier.tool import ZapierNLARunAction\n",
        "\n",
        "# https://nla.zapier.com/docs/authentication/\n",
        "os.environ[\"ZAPIER_NLA_API_KEY\"] = getpass(\"Your Zapier NLA Key: \")"
      ],
      "metadata": {
        "id": "zE7zTpfILy5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agency_swarm import BaseTool\n",
        "from pydantic import Field\n",
        "\n",
        "actions = ZapierNLAWrapper().list()\n",
        "\n",
        "class FindEmail(BaseTool):\n",
        "    \"\"\"Use this tool to find an email in user's mailbox\"\"\"\n",
        "    instructions: str = Field(..., description=\"The search phrase you want to use to find a relevant email.\")\n",
        "\n",
        "    def run(self):\n",
        "      action = next(\n",
        "          (a for a in actions if a[\"description\"].startswith(\"Gmail: Find Email\")), None\n",
        "      )\n",
        "      return str(ZapierNLARunAction(\n",
        "              action_id=action[\"id\"],\n",
        "              zapier_description=action[\"description\"],\n",
        "              params_schema=action[\"params\"],\n",
        "          ).run(self.search_string))\n",
        "\n",
        "class DraftEmail(BaseTool):\n",
        "    \"\"\"Use this tool to draft a response email\"\"\"\n",
        "    instructions: str = Field(..., description=\"Clearly outline in natural language the content of the email you need to draft and the address of the recepient.\")\n",
        "\n",
        "    def run(self):\n",
        "        action = next(\n",
        "            (a for a in actions if a[\"description\"].startswith(\"Gmail: Create Draft Reply\")), None\n",
        "        )\n",
        "        return str(ZapierNLARunAction(\n",
        "                action_id=action[\"id\"],\n",
        "                zapier_description=action[\"description\"],\n",
        "                params_schema=action[\"params\"],\n",
        "            ).run(self.instructions))"
      ],
      "metadata": {
        "id": "w2OO-KxEuh8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom tools with [Instructor](https://github.com/jxnl/instructor)"
      ],
      "metadata": {
        "id": "B5m14T_KhwFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from duckduckgo_search import DDGS\n",
        "from agency_swarm.util.oai import get_openai_client\n",
        "\n",
        "client = get_openai_client()\n",
        "\n",
        "\n",
        "class SearchWeb(BaseTool):\n",
        "    \"\"\"Search the web with a search phrase and return the results.\"\"\"\n",
        "\n",
        "    phrase: str = Field(..., description=\"The search phrase you want to use. Optimize the search phrase for an internet search engine.\")\n",
        "\n",
        "    # This code will be executed if the agent calls this tool\n",
        "    def run(self):\n",
        "      with DDGS() as ddgs:\n",
        "        return str([r for r in ddgs.text(self.phrase, max_results=3)])\n",
        "\n",
        "class GenerateProposal(BaseTool):\n",
        "    \"\"\"Generate a proposal for a project based on a project brief. Remember that user does not have access to the output of this function. You must send it back to him after execution.\"\"\"\n",
        "    project_brief: str = Field(..., description=\"The project breif to generate a proposal for.\")\n",
        "\n",
        "    def run(self):\n",
        "        completion = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "              {\"role\": \"system\", \"content\": \"You are a professional proposal drafting assistant. Do not include any actual technologies or technical details into proposal until specified in the project brief. Be short.\"},\n",
        "              {\"role\": \"user\", \"content\": \"Please draft a proposal for the ollowing project brief: \" + self.project_brief}\n",
        "            ]\n",
        "          )\n",
        "\n",
        "        return str(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "MxkO2GHnNekC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "va_instructions = \"\"\"### Instructions for Virtual Assistant\n",
        "\n",
        "Your role is to assist users in executing tasks like below. If the task is outside of your capabilities, please report back to the user.\n",
        "\n",
        "#### 1. Drafting Emails\n",
        "   - **Understand Context and Tone**: Familiarize yourself with the context of each email. Maintain a professional and courteous tone.\n",
        "   - **Accuracy and Clarity**: Ensure that the information is accurate and presented clearly. Avoid jargon unless it's appropriate for the recipient.\n",
        "\n",
        "#### 2. Generating Proposals\n",
        "   - **Gather Requirements**: Collect all necessary information about the project, including client needs, objectives, and any specific requests.\n",
        "\n",
        "#### 3. Conducting Research\n",
        "   - **Understand the Objective**: Clarify the purpose and objectives of the research to focus on relevant information.\n",
        "   - **Summarize Findings**: Provide clear, concise summaries of the research findings, highlighting key points and how they relate to the project or inquiry.\n",
        "   - **Cite Sources**: Properly cite all sources to maintain integrity and avoid plagiarism.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "8u4x6gdeSARg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "va = Agent(name=\"Virtual Assistant\",\n",
        "            description=\"Responsible for drafting emails, doing research and writing proposals.\",\n",
        "            instructions=va_instructions,\n",
        "            files_folder=None,\n",
        "            tools=[SearchWeb, FindEmail, DraftEmail, GenerateProposal])"
      ],
      "metadata": {
        "id": "6e8aWSRRBlBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Developer Agent"
      ],
      "metadata": {
        "id": "x0zLIv1i75gJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agency_swarm.tools import BaseTool\n",
        "from pydantic import Field, BaseModel\n",
        "import subprocess\n",
        "from typing import List\n",
        "\n",
        "\n",
        "class ExecuteCommand(BaseTool):\n",
        "    \"\"\"Run any command from the terminal. If there are too many logs, the outputs might be truncated.\"\"\"\n",
        "    command: str = Field(\n",
        "        ..., description=\"The command to be executed.\"\n",
        "    )\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Executes the given command and captures its output and errors.\"\"\"\n",
        "        try:\n",
        "            # Splitting the command into a list of arguments\n",
        "            command_args = self.command.split()\n",
        "\n",
        "            # Executing the command\n",
        "            result = subprocess.run(\n",
        "                command_args,\n",
        "                text=True,\n",
        "                capture_output=True,\n",
        "                check=True\n",
        "            )\n",
        "            return result.stdout\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            return f\"An error occurred: {e.stderr}\"\n",
        "\n",
        "class File(BaseTool):\n",
        "    \"\"\"\n",
        "    File to be written to the disk with an appropriate name and file path, containing code that can be saved and executed locally at a later time.\n",
        "    \"\"\"\n",
        "    file_name: str = Field(\n",
        "        ..., description=\"The name of the file including the extension and the file path from your current directory if needed.\"\n",
        "    )\n",
        "    body: str = Field(..., description=\"Correct contents of a file\")\n",
        "\n",
        "    def run(self):\n",
        "        # Extract the directory path from the file name\n",
        "        directory = os.path.dirname(self.file_name)\n",
        "\n",
        "        # If the directory is not empty, check if it exists and create it if not\n",
        "        if directory and not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "\n",
        "        # Write the file\n",
        "        with open(self.file_name, \"w\") as f:\n",
        "            f.write(self.body)\n",
        "\n",
        "        return \"File written to \" + self.file_name\n",
        "\n",
        "class Program(BaseTool):\n",
        "    \"\"\"\n",
        "    Set of files that represent a complete and correct program. This environment has access to all standard Python packages and the internet.\n",
        "    \"\"\"\n",
        "    chain_of_thought: str = Field(...,\n",
        "        description=\"Think step by step to determine the correct actions that are needed to implement the program.\")\n",
        "    files: List[File] = Field(..., description=\"List of files\")\n",
        "\n",
        "    def run(self):\n",
        "      outputs = []\n",
        "      for file in self.files:\n",
        "        outputs.append(file.run())\n",
        "\n",
        "      return str(outputs)"
      ],
      "metadata": {
        "id": "aIhhoDWx8BZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_instructions = \"\"\"# Instructions for AI Developer Agent\n",
        "\n",
        "- Write clean and efficient Python code.\n",
        "- Structure your code logically, with `main.py` as the entry point.\n",
        "- Ensure correct imports according to program structure.\n",
        "- Execute your code to test for functionality and errors, before reporting back to the user.\n",
        "- Anticipate and handle potential runtime errors.\n",
        "- Provide clear error messages for easier troubleshooting.\n",
        "- Debug any issues before reporting the results back to the user.\"\"\""
      ],
      "metadata": {
        "id": "lStK381cVF7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agency_swarm.tools import Retrieval, CodeInterpreter\n",
        "\n",
        "dev = Agent(name=\"Developer\",\n",
        "            description=\"Responsible for running and executing Python Programs.\",\n",
        "            instructions=dev_instructions,\n",
        "            files_folder=None,\n",
        "            tools=[ExecuteCommand, Program])\n"
      ],
      "metadata": {
        "id": "7nAlYUHd74pX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Agency\n",
        "\n",
        "`shared_instructions` will be shared accross all agents."
      ],
      "metadata": {
        "id": "8kXMaOqSSb_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agency_manifesto = \"\"\"# \"VRSEN AI\" Agency Manifesto\n",
        "\n",
        "You are a part of a virtual AI development agency called \"VRSEN AI\"\n",
        "\n",
        "Your mission is to empower businesses to navigate the AI revolution successfully.\"\"\""
      ],
      "metadata": {
        "id": "7rer151XX8Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agency_swarm import Agency\n",
        "\n",
        "agency = Agency([\n",
        "    ceo,\n",
        "    [ceo, dev],\n",
        "    [ceo, va],\n",
        "    [dev, va]\n",
        "], shared_instructions=agency_manifesto)"
      ],
      "metadata": {
        "id": "mr2apzHySegB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Demo"
      ],
      "metadata": {
        "id": "I2CHn1B7ShEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agency.demo_gradio(height=900)"
      ],
      "metadata": {
        "id": "vpGRiEeulQZv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "90ffc33b-b3c6-488f-f4a1-d4813376872d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/components/chatbot.py:282: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e0eb128868158644d0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e0eb128868158644d0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Gradio Blocks instance: 6 backend functions\n",
              "-------------------------------------------\n",
              "fn_index=0\n",
              " inputs:\n",
              " |-<gradio.components.textbox.Textbox object at 0x7e498096ac10>\n",
              " |-<gradio.components.chatbot.Chatbot object at 0x7e4980b06ad0>\n",
              " outputs:\n",
              " |-<gradio.components.textbox.Textbox object at 0x7e498096ac10>\n",
              " |-<gradio.components.chatbot.Chatbot object at 0x7e4980b06ad0>\n",
              "fn_index=1\n",
              " inputs:\n",
              " |-<gradio.components.textbox.Textbox object at 0x7e498096ac10>\n",
              " |-<gradio.components.chatbot.Chatbot object at 0x7e4980b06ad0>\n",
              " |-<gradio.components.dropdown.Dropdown object at 0x7e4980b07b90>\n",
              " outputs:\n",
              " |-<gradio.components.textbox.Textbox object at 0x7e498096ac10>\n",
              " |-<gradio.components.chatbot.Chatbot object at 0x7e4980b06ad0>\n",
              " |-<gradio.components.dropdown.Dropdown object at 0x7e4980b07b90>\n",
              "fn_index=2\n",
              " inputs:\n",
              " |-<gradio.components.dropdown.Dropdown object at 0x7e4980b07b90>\n",
              " outputs:\n",
              "fn_index=3\n",
              " inputs:\n",
              " |-<gradio.templates.Files object at 0x7e4980965a90>\n",
              " outputs:\n",
              "fn_index=4\n",
              " inputs:\n",
              " |-<gradio.components.textbox.Textbox object at 0x7e498096ac10>\n",
              " |-<gradio.components.chatbot.Chatbot object at 0x7e4980b06ad0>\n",
              " outputs:\n",
              " |-<gradio.components.textbox.Textbox object at 0x7e498096ac10>\n",
              " |-<gradio.components.chatbot.Chatbot object at 0x7e4980b06ad0>\n",
              "fn_index=5\n",
              " inputs:\n",
              " |-<gradio.components.textbox.Textbox object at 0x7e498096ac10>\n",
              " |-<gradio.components.chatbot.Chatbot object at 0x7e4980b06ad0>\n",
              " |-<gradio.components.dropdown.Dropdown object at 0x7e4980b07b90>\n",
              " outputs:\n",
              " |-<gradio.components.textbox.Textbox object at 0x7e498096ac10>\n",
              " |-<gradio.components.chatbot.Chatbot object at 0x7e4980b06ad0>\n",
              " |-<gradio.components.dropdown.Dropdown object at 0x7e4980b07b90>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}